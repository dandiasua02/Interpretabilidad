{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1cc834",
   "metadata": {},
   "source": [
    "<h1>Proyecto sobre interpretabilidad sobre modelos de caja negra</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43eb70d",
   "metadata": {},
   "source": [
    "<p>En este proyecto nos dedicaremos a realizar el entrenamiento para los modelos de interpretabilidad de modelos de caja negra,en nuestro proyecto hemos realizado hacer el entrenamiento de modelos para tareas de clasifiacacion. Adelante en esta practica primero realizaremos el entrenamiento de los diferentes modelos de caja negra primero realizaremos el entrenamiento a un modelo de redes neuronales.</p>\n",
    "<u><b>A continuacion el siguiente bloque de codigo es necesario ejecutarlo para el correcto funcionamiento de este notebook.</b></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb58403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "from tensorflow import get_logger\n",
    "get_logger().setLevel('ERROR')\n",
    "import random\n",
    "from tensorflow import random as tensorflow_random\n",
    "\n",
    "random.seed(2398572)\n",
    "tensorflow_random.set_seed(394867)\n",
    "\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "\n",
    "np.random.seed(43958734)\n",
    "np.set_printoptions(threshold=10)\n",
    "from tensorflow import keras\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d1334",
   "metadata": {},
   "source": [
    "<p>Ahora vamos a seleccionar el primer csv que contiene los datos y seleccionaremos los atributos que tendremos en cuenta para hacer el entrenamiento del algoritmo</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20fa650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record_ID</th>\n",
       "      <th>Auction_ID</th>\n",
       "      <th>Bidder_ID</th>\n",
       "      <th>Bidder_Tendency</th>\n",
       "      <th>Bidding_Ratio</th>\n",
       "      <th>Successive_Outbidding</th>\n",
       "      <th>Last_Bidding</th>\n",
       "      <th>Auction_Bids</th>\n",
       "      <th>Starting_Price_Average</th>\n",
       "      <th>Early_Bidding</th>\n",
       "      <th>Winning_Ratio</th>\n",
       "      <th>Auction_Duration</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>732</td>\n",
       "      <td>_***i</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>732</td>\n",
       "      <td>g***r</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>732</td>\n",
       "      <td>t***p</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>732</td>\n",
       "      <td>7***n</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>z***z</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Record_ID  Auction_ID Bidder_ID  Bidder_Tendency  Bidding_Ratio  \\\n",
       "0          1         732     _***i         0.200000       0.400000   \n",
       "1          2         732     g***r         0.024390       0.200000   \n",
       "2          3         732     t***p         0.142857       0.200000   \n",
       "3          4         732     7***n         0.100000       0.200000   \n",
       "4          5         900     z***z         0.051282       0.222222   \n",
       "\n",
       "   Successive_Outbidding  Last_Bidding  Auction_Bids  Starting_Price_Average  \\\n",
       "0                    0.0      0.000028           0.0                0.993593   \n",
       "1                    0.0      0.013123           0.0                0.993593   \n",
       "2                    0.0      0.003042           0.0                0.993593   \n",
       "3                    0.0      0.097477           0.0                0.993593   \n",
       "4                    0.0      0.001318           0.0                0.000000   \n",
       "\n",
       "   Early_Bidding  Winning_Ratio  Auction_Duration  Class  \n",
       "0       0.000028       0.666667                 5      0  \n",
       "1       0.013123       0.944444                 5      0  \n",
       "2       0.003042       1.000000                 5      0  \n",
       "3       0.097477       1.000000                 5      0  \n",
       "4       0.001242       0.500000                 7      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shill_bidding = pandas.read_csv(\"Shill Bidding Dataset.csv\")\n",
    "shill_bidding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d411b193",
   "metadata": {},
   "source": [
    "Seleccionamos los atributos a tener encuenta a la hora de entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9178f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.00000000e-01 4.00000000e-01 0.00000000e+00 ... 2.77778000e-05\n",
      "  6.66666667e-01 5.00000000e+00]\n",
      " [2.43902440e-02 2.00000000e-01 0.00000000e+00 ... 1.31226852e-02\n",
      "  9.44444444e-01 5.00000000e+00]\n",
      " [1.42857143e-01 2.00000000e-01 0.00000000e+00 ... 3.04166670e-03\n",
      "  1.00000000e+00 5.00000000e+00]\n",
      " ...\n",
      " [5.55555560e-02 4.34782610e-02 0.00000000e+00 ... 1.56630291e-02\n",
      "  0.00000000e+00 7.00000000e+00]\n",
      " [7.69230770e-02 8.69565220e-02 0.00000000e+00 ... 4.15013200e-04\n",
      "  0.00000000e+00 7.00000000e+00]\n",
      " [1.63934430e-02 4.34782610e-02 0.00000000e+00 ... 3.40350529e-01\n",
      "  0.00000000e+00 7.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "atributos = shill_bidding.loc[:,'Bidder_Tendency':'Auction_Duration']\n",
    "atributos = atributos.to_numpy()\n",
    "print(atributos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d340d5",
   "metadata": {},
   "source": [
    "<p>Vamos a seleccionar el atributo objetivo para el algoritmo</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a025f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "objetivo = shill_bidding['Class']\n",
    "objetivo = objetivo.to_numpy()\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9522fa6c",
   "metadata": {},
   "source": [
    "Entrenamos el modelo de redes neuronales y dividimos el modelo de entrenamiento con el modelo de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34611bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "    atributos, objetivo, test_size=.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c756ab",
   "metadata": {},
   "source": [
    "Input indica el numero de dimensiones y dense indica cantidad de neuronas y la funcion de activacion, que por defecto es la identidad. Este ejemplo es para modelos de <b>clasificacion</b> \n",
    "\n",
    "La red neuronal posee una única capa (aparte de la de entrada) que proporciona como salida un array bidimensional None x 1 (es decir, para cada ejemplo proporciona un valor) y 9 parámetros (el peso de la conexión de cada entrada con la neurona de la capa más el sesgo de la neurona) entrenables (la red los aprenderá mediante el algoritmo de entrenamiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252f2b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_bidding = keras.Sequential()\n",
    "red_bidding.add(keras.Input(shape=(9,)))\n",
    "red_bidding.add(keras.layers.Dense(10, activation='relu'))\n",
    "red_bidding.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c0c79",
   "metadata": {},
   "source": [
    "Los pesos y sesgos de la red se guardan en el atributo weights (son los arrays asociados al argumento numpy en la estructura de datos guardada en ese atributo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9cc99e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                100       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(9, 10) dtype=float32, numpy=\n",
       " array([[ 0.16066974, -0.1832436 , -0.3538186 , ...,  0.340855  ,\n",
       "          0.25578886,  0.5128347 ],\n",
       "        [-0.1894975 , -0.0651882 , -0.12789819, ..., -0.19957277,\n",
       "         -0.0312627 , -0.17042843],\n",
       "        [-0.4715354 , -0.20407248,  0.29305267, ..., -0.50047326,\n",
       "          0.43153203,  0.34140068],\n",
       "        ...,\n",
       "        [-0.01709646, -0.03771824, -0.15322047, ...,  0.49320394,\n",
       "          0.24029279, -0.05415136],\n",
       "        [ 0.2125234 ,  0.41607064, -0.06427649, ..., -0.03796834,\n",
       "          0.12062675,  0.19724232],\n",
       "        [ 0.27244765,  0.48618132,  0.47343248, ...,  0.20641726,\n",
       "          0.0910573 ,  0.37640864]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(10, 1) dtype=float32, numpy=\n",
       " array([[ 0.57531995],\n",
       "        [ 0.17448515],\n",
       "        [-0.48876932],\n",
       "        [ 0.38587934],\n",
       "        [ 0.21933508],\n",
       "        [ 0.03731865],\n",
       "        [-0.10164666],\n",
       "        [ 0.24462742],\n",
       "        [ 0.00295365],\n",
       "        [ 0.24534315]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_bidding.summary()\n",
    "red_bidding.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aad118",
   "metadata": {},
   "source": [
    "Entrenamos la red neuronal con un optimizador y una funcion de perdida, en este caso al tratarse de un modelo de clasifiacion seleccionamos la funcion de perdida como la entropia cruzada binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011b2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_bidding.compile(optimizer='SGD', loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08890c73",
   "metadata": {},
   "source": [
    "Aqui entrenamos el modelo con los atributos de prueba seleccionados y el objetivo de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "424e4938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "538/538 [==============================] - 1s 1ms/step - loss: 0.3997 - accuracy: 0.8773\n",
      "Epoch 2/10\n",
      "538/538 [==============================] - 1s 1ms/step - loss: 0.3068 - accuracy: 0.8954\n",
      "Epoch 3/10\n",
      "538/538 [==============================] - 1s 1ms/step - loss: 0.2324 - accuracy: 0.9149\n",
      "Epoch 4/10\n",
      "538/538 [==============================] - 1s 1ms/step - loss: 0.1664 - accuracy: 0.9509\n",
      "Epoch 5/10\n",
      "538/538 [==============================] - 1s 1ms/step - loss: 0.1228 - accuracy: 0.9630\n",
      "Epoch 6/10\n",
      "538/538 [==============================] - 1s 1ms/step - loss: 0.0970 - accuracy: 0.9635\n",
      "Epoch 7/10\n",
      "538/538 [==============================] - 1s 1ms/step - loss: 0.0829 - accuracy: 0.9631\n",
      "Epoch 8/10\n",
      "538/538 [==============================] - 1s 1ms/step - loss: 0.0740 - accuracy: 0.9671\n",
      "Epoch 9/10\n",
      "538/538 [==============================] - 1s 1ms/step - loss: 0.0686 - accuracy: 0.9678\n",
      "Epoch 10/10\n",
      "538/538 [==============================] - 1s 1ms/step - loss: 0.0644 - accuracy: 0.9685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x230b8ac5ae0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_bidding.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "               batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae171db8",
   "metadata": {},
   "source": [
    "Y ahora vamos a evaluar el modelo y ejecutar su prediccion con los atributos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dc8923e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9715\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Buenos resultados: 922\n",
      "Malos resultados: 27\n",
      "La precision es:  0.925531914893617\n"
     ]
    }
   ],
   "source": [
    "red_bidding.evaluate(atributos_prueba, objetivo_prueba)\n",
    "red_bidding.predict(atributos_prueba)\n",
    "j = 0\n",
    "vp=0\n",
    "vn=0\n",
    "fp=0\n",
    "fn=0\n",
    "for i in red_bidding.predict(atributos_prueba):\n",
    "    \n",
    "    if(i > 0.5):\n",
    "        i = 1\n",
    "    elif(i <= 0.5):\n",
    "        i = 0\n",
    "    if(i == objetivo_prueba[j] and i == 1):\n",
    "        vp+=1\n",
    "    elif(i !=objetivo_prueba[j] and i == 1):\n",
    "        fp +=1\n",
    "    elif(i ==objetivo_prueba[j] and i == 0):\n",
    "        vn +=1\n",
    "    elif(i !=objetivo_prueba[j] and i == 0):\n",
    "        fn +=1\n",
    "    j+=1\n",
    "    \n",
    "print(\"Buenos resultados:\", vp+vn)\n",
    "print(\"Malos resultados:\", fp+fn)\n",
    "print(\"La precision es: \", vp/(vp+fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c45d0f",
   "metadata": {},
   "source": [
    "# El siguiente modelo a realizar es random forest (ChatGPT dice que es el mas sencillo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9751681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c80c4942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.00000000e-01 4.00000000e-01 0.00000000e+00 ... 2.77778000e-05\n",
      "  6.66666667e-01 5.00000000e+00]\n",
      " [2.43902440e-02 2.00000000e-01 0.00000000e+00 ... 1.31226852e-02\n",
      "  9.44444444e-01 5.00000000e+00]\n",
      " [1.42857143e-01 2.00000000e-01 0.00000000e+00 ... 3.04166670e-03\n",
      "  1.00000000e+00 5.00000000e+00]\n",
      " ...\n",
      " [5.55555560e-02 4.34782610e-02 0.00000000e+00 ... 1.56630291e-02\n",
      "  0.00000000e+00 7.00000000e+00]\n",
      " [7.69230770e-02 8.69565220e-02 0.00000000e+00 ... 4.15013200e-04\n",
      "  0.00000000e+00 7.00000000e+00]\n",
      " [1.63934430e-02 4.34782610e-02 0.00000000e+00 ... 3.40350529e-01\n",
      "  0.00000000e+00 7.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo CSV\n",
    "data = pandas.read_csv('Shill Bidding Dataset.csv')\n",
    "\n",
    "# Separar los atributos (X) y el objetio (y)\n",
    "# Ajusta 'etiqueta' al nombre de la columna objetivo\n",
    "X = data[['Bidder_Tendency','Bidding_Ratio', 'Successive_Outbidding', 'Last_Bidding','Auction_Bids', 'Starting_Price_Average', 'Early_Bidding','Winning_Ratio', 'Auction_Duration']]\n",
    "X = X.to_numpy()\n",
    "y = data['Class']\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# n_stimators = numero de arboles y max_depth profundidad maxima de cada arbol \n",
    "randomForest_Bidding = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d57b11c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo con los datos\n",
    "randomForest_Bidding.fit(X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82ac9841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buenos resultados: 1255\n",
      "Malos resultados: 10\n",
      "La precision es:  0.9357142857142857\n"
     ]
    }
   ],
   "source": [
    "predictions = randomForest_Bidding.predict(X_test)\n",
    "# Esto lo realizamos para poder visualizar una aproximacion\n",
    "j = 0\n",
    "vp=0\n",
    "vn=0\n",
    "fp=0\n",
    "fn=0\n",
    "for prediction, true_label in zip(predictions, y_test):\n",
    "    if(prediction == true_label and prediction == 1  ):\n",
    "        vp+=1\n",
    "    elif(prediction != true_label and prediction == 1):\n",
    "        fp +=1\n",
    "    elif(prediction == true_label and prediction == 0):\n",
    "        vn +=1\n",
    "    elif(prediction != true_label and prediction == 0):\n",
    "        fn +=1\n",
    "    j+=1\n",
    "    \n",
    "print(\"Buenos resultados:\", vp+vn)\n",
    "print(\"Malos resultados:\", fp+fn)\n",
    "print(\"La precision es: \", vp/(vp+fp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656abee",
   "metadata": {},
   "source": [
    "# Este es el modelo LIME de interpretabilidad de modelos de caja negra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c27b43",
   "metadata": {},
   "source": [
    "Este es el modelo de Lime que funciona podemos modificarlo averiguando la distancia con otro calculo como el de arriba y haciendo llamdas recursivas a funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d3a837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definitivo\n",
    "\n",
    "\n",
    "#PARECE QUE ESTE TIENE BUENA PINTA \n",
    "def perturb(datos, cabecera):\n",
    "    k = random.randint(1, len(datos))\n",
    "    datos_perturbados = datos.copy()\n",
    "    for j in range(k):\n",
    "        atributo_a_perturbar = random.randint(0,len(datos)-1)\n",
    "        rango_maximo = abs(max(a[atributo_a_perturbar] for a in cabecera))\n",
    "        rango_minimo = abs(min(a[atributo_a_perturbar] for a in cabecera))\n",
    "        datos_perturbados[atributo_a_perturbar] = random.uniform(rango_minimo, rango_maximo)\n",
    "    return datos_perturbados\n",
    "\n",
    "def explicacion_del_modelo(N,f,datos, cabecera):\n",
    "    X = [] # Muestras perturbadas\n",
    "    R = [] # Representaciones\n",
    "    W = [] # Distancias entre muestra x y sus perturbaciones\n",
    "    for i in range(N):\n",
    "        datos_perturbados= perturb(datos, cabecera)\n",
    "        w = abs(sum(datos[atributo] - datos_perturbados[atributo] for atributo in range(0, len(datos)-1)))\n",
    "        r = [0 if datos_perturbados[atributo] == datos[atributo] else 1 for atributo in range(0,len(datos)-1)]\n",
    "        X.append(datos_perturbados)\n",
    "        R.append(r)\n",
    "        W.append(w)\n",
    "    X = np.expand_dims(datos_perturbados, axis=0)\n",
    "    Y_perturbada = f.predict(X)\n",
    "    G = Ridge()\n",
    "    G.fit(R, Y_perturbada, sample_weight=W)\n",
    "    return G.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03e02101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "{'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}\n",
      "{'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Ridge\n",
    "# Ejemplo utilizando el modelo \"red_bidding\" definido en el código anterior\n",
    "parametros = explicacion_del_modelo(1, red_bidding, atributos[5809], atributos)\n",
    "params = explicacion_del_modelo(1, randomForest_Bidding, atributos[5809], atributos)\n",
    "print(parametros)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc5660",
   "metadata": {},
   "source": [
    "<p><strong>Alpha:</strong> Este parámetro controla la fuerza de la regularización en el modelo Ridge. Cuanto mayor sea el valor de alpha, mayor será la penalización aplicada a los coeficientes. Un valor de alpha igual a 1.0 indica una regularización moderada.</p>\n",
    "\n",
    "<p><strong>Copy_X:</strong> Es un parámetro booleano que indica si los datos de entrada deben ser copiados antes de ajustar el modelo. Si se establece en True, se realiza una copia de los datos; si se establece en False, los datos se sobrescriben.</p>\n",
    "\n",
    "<p><strong>Fit_intercept:</strong> Es un parámetro booleano que indica si se debe ajustar un intercepto en el modelo. Si se establece en True, el modelo incluirá un término constante; si se establece en False, el modelo no incluirá un término constante.</p>\n",
    "\n",
    "<p><strong>Max_iter:</strong> Es el número máximo de iteraciones permitidas durante el ajuste del modelo. Si se establece en None, el modelo ajustará hasta que la convergencia sea alcanzada.</p>\n",
    "\n",
    "<p><strong>Positive:</strong> Es un parámetro booleano que indica si los coeficientes deben ser no negativos. Si se establece en True, se restringe que los coeficientes sean siempre positivos.</p>\n",
    "\n",
    "<p><strong>Random_state:</strong> Este parámetro controla la semilla utilizada por el generador de números aleatorios. Si se establece en None, el generador de números aleatorios utilizará una semilla diferente en cada ejecución.</p>\n",
    "\n",
    "<p><strong>Solver:</strong> Especifica el algoritmo a utilizar en el ajuste del modelo. Si se establece en 'auto', el modelo seleccionará automáticamente el mejor algoritmo según los datos y el problema en cuestión.</p>\n",
    "\n",
    "<p><strong>Tol:</strong> Especifica la tolerancia para el criterio de parada en el ajuste del modelo. Si la diferencia entre dos iteraciones consecutivas es menor que la tolerancia, el ajuste se considera convergido.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713ce54",
   "metadata": {},
   "source": [
    "# Aqui tenemos los calculos requeridos sobre el trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8157479b",
   "metadata": {},
   "source": [
    " <h1>Resumen de cálculos</h1>\n",
    "\n",
    "  <i><b>1. Identidad:</b></i>\n",
    "  <p>Verifica si las explicaciones son idénticas para objetos idénticos.</p>\n",
    "\n",
    " <i><b>2. Separabilidad:</b></i>\n",
    "  <p>Verifica que las explicaciones sean diferentes para objetos no idénticos.</p>\n",
    "\n",
    " <i><b>3. Estabilidad:</b></i>\n",
    "  <p>Evalúa si objetos similares tienen explicaciones similares mediante la correlación de Spearman.</p>\n",
    "\n",
    "  <i><b>4. Selectividad:</b></i>\n",
    "  <p>Mide el efecto de eliminar variables relevantes en la predicción mediante el cálculo del área bajo la curva (AUC).</p>\n",
    "\n",
    "  <i><b>5. Completitud (Coherencia):</b></i>\n",
    "  <p>Calcula la coherencia de una muestra al eliminar características no importantes.</p>\n",
    "\n",
    "  <i><b>6. Completitud (Coherencia / Explicación):</b></i>\n",
    "  <p>Calcula la coherencia promedio y la desviación estándar de la coherencia.</p>\n",
    "\n",
    " <i><b>7. Completitud (Congruencia):</b></i>\n",
    "  <p>Calcula la desviación estándar de la coherencia como un proxy de congruencia.</p>\n",
    "\n",
    "<b> CABE DESTACAR QUE ESTOS CALCULOS ESTAN REALIZADOS DE MOMENTO CON VALORES ARBITRARIOS ES DECIR DEBEMOS DE OBTENER PRIMERO LOS VALORES DE LOS CALCULOS QUE DEBEMOS REALIZAR</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afec3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Segunda vuelta de campana\n",
    "\n",
    "# Distancias entre objetos\n",
    "def object_distance(X_train, X_test, model):\n",
    "    # Obtener las predicciones del modelo para los datos de entrenamiento y prueba\n",
    "    predictions_train = model.predict(X_train)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    predictions_train = predictions_train.reshape(-1, 1)\n",
    "    predictions_test = predictions_test.reshape(-1, 1)\n",
    "    # Calcular la distancia de objetos entre cada par de predicciones\n",
    "    object_distances = cdist(predictions_train, predictions_test)\n",
    "    \n",
    "    return object_distances\n",
    "\n",
    "# Distancias entre explicaciones\n",
    "def explanation_distance(X_train, X_test, model):\n",
    "    # Obtener las predicciones del modelo para los datos de entrenamiento y prueba\n",
    "        \n",
    "    predictions_train = randomForest_Bidding.predict(X_train)\n",
    "    predictions_test = randomForest_Bidding.predict(X_test)\n",
    "\n",
    "    # Calcular la distancia de explicaciones entre cada par de predicciones\n",
    "    explanation_distances = np.linalg.norm(predictions_train - predictions_test, axis=1)\n",
    "\n",
    "    return explanation_distances\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def identidad_(dist_objetos, dist_explicaciones):\n",
    "    identidad = np.all(dist_objetos == 0) and np.all(dist_explicaciones == 0)\n",
    "    return identidad\n",
    "    \n",
    "def separabilidad_(dist_objetos, dist_explicaciones):\n",
    "    separabilidad = np.all(dist_objetos != 0) and np.all(dist_explicaciones > 0)\n",
    "    return separabilidad\n",
    "\n",
    "def estabilidad_(dist_objetos, dist_explicaciones):\n",
    "    correlacion = [spearmanr(dist_objetos[i], dist_explicaciones[i]).correlation for i in range(len(dist_objetos))]\n",
    "    estabilidad = all(corr > 0 for corr in correlacion)\n",
    "    return estabilidad\n",
    "\n",
    "def selectividad_(muestras, n_caracteristicas, modelo):\n",
    "    for i in range(n_caracteristicas):\n",
    "        muestras_modificadas = np.copy(muestras)\n",
    "        muestras_modificadas[:, i] = 0\n",
    "        \n",
    "        # Obtener las etiquetas binarias para la característica i\n",
    "        y_true = np.where(muestras[:, i] == 0, 0, 1)\n",
    "        y_true_binary = label_binarize(y_true, classes=np.unique(y_true))\n",
    "        \n",
    "        # Obtener las predicciones del modelo con la característica i eliminada\n",
    "        y_score = modelo.predict(muestras_modificadas)\n",
    "        \n",
    "        # Calcular el área bajo la curva (AUC) y almacenarlo en auc_scores\n",
    "        if len(np.unique(y_true_binary)) > 1:\n",
    "            auc_scores.append(roc_auc_score(y_true_binary, y_score))\n",
    "    \n",
    "    if auc_scores:\n",
    "        selectividad = np.mean(auc_scores)\n",
    "    else:\n",
    "        selectividad = 0.0\n",
    "    \n",
    "    return selectividad\n",
    "\n",
    "def coherencia_(prediccion_original, prediccion_nueva):\n",
    "    # Obtener las predicciones del modelo para la señal original y la nueva señal\n",
    "    # Calcular el error de predicción para la señal original\n",
    "    error_original = np.abs(predicciones_original - prediccion_nueva)\n",
    "    # Calcular el error de predicción para la nueva señal\n",
    "    error_nueva = np.abs(predicciones_nueva - y_nueva)\n",
    "    coherencia = np.abs(prediction_original - prediction_nueva)\n",
    "    return coherencia\n",
    "def completitud_(prediccion_original, y_test):\n",
    "    pi_e= np.mean(prediccion_original != y_test)\n",
    "    ei_e = np.mean(np.abs(prediccion_original - y_original))\n",
    "    completitud = np.abs(ei_e / pi_e) \n",
    "    return completitud\n",
    "    \n",
    "def congruencia_(coherencia):\n",
    "    #Congruencia\n",
    "    alpha = np.mean(completeness)  # alpha_values es una lista/array con los valores de coherencia alpha_i\n",
    "\n",
    "    # Calcular la desviación estándar de la coherencia\n",
    "    N = len(data)\n",
    "    delta = np.sqrt(np.mean((completeness - alpha)**2) / N)  # N es el número total de muestras\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c09285c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5056,) (1265,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m predicciones_nueva \u001b[38;5;241m=\u001b[39m randomForest_Bidding\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m dist_objetos \u001b[38;5;241m=\u001b[39m object_distance(X_train, X_test, randomForest_Bidding)\n\u001b[1;32m----> 5\u001b[0m dist_explicaciones \u001b[38;5;241m=\u001b[39m \u001b[43mexplanation_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomForest_Bidding\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 23\u001b[0m, in \u001b[0;36mexplanation_distance\u001b[1;34m(X_train, X_test, model)\u001b[0m\n\u001b[0;32m     20\u001b[0m predictions_test \u001b[38;5;241m=\u001b[39m randomForest_Bidding\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Calcular la distancia de explicaciones entre cada par de predicciones\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m explanation_distances \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(\u001b[43mpredictions_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredictions_test\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m explanation_distances\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5056,) (1265,) "
     ]
    }
   ],
   "source": [
    "#Valores de funciones\n",
    "predicciones_original = randomForest_Bidding.predict(X_train)\n",
    "predicciones_nueva = randomForest_Bidding.predict(X_test)\n",
    "dist_objetos = object_distance(X_train, X_test, randomForest_Bidding)\n",
    "dist_explicaciones = explanation_distance(X_train, X_test, randomForest_Bidding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a29d88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_distance(X_train,X_test, randomForest_Bidding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78acb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b30b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
